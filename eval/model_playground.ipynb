{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Model Playground\n",
    "\n",
    "Interactive exploration of the trained MiniCPM embedding model.\n",
    "Compare base vs fine-tuned embeddings, visualise similarity structure, and sanity-check on custom inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), \"mteb\"))\n",
    "\n",
    "from model.minicpm import MiniCPM\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "MODEL_PATH = \"../pretrained/MiniCPM-2B-dpo-bf16\"\n",
    "ADAPTER_PATH = \"../train/output/20260221004650\"  # latest training run\n",
    "\n",
    "# Load both base and fine-tuned models\n",
    "print(\"Loading base model...\")\n",
    "base_model = MiniCPM(model_path=MODEL_PATH)\n",
    "print(\"Loading fine-tuned model...\")\n",
    "ft_model = MiniCPM(model_path=MODEL_PATH, adapter_path=ADAPTER_PATH)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Cosine similarity: base vs fine-tuned\n",
    "\n",
    "Compare how the two models score sentence pairs of varying similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "pairs = [\n",
    "    # High similarity\n",
    "    (\"A cat is sitting on the mat.\", \"A kitten sits on a rug.\"),\n",
    "    (\"The stock market crashed today.\", \"Shares plummeted in today's trading.\"),\n",
    "    # Medium similarity\n",
    "    (\"A cat is sitting on the mat.\", \"A dog is lying on the floor.\"),\n",
    "    (\"The weather is nice today.\", \"It's sunny outside.\"),\n",
    "    # Low similarity\n",
    "    (\"A cat is sitting on the mat.\", \"The stock market crashed today.\"),\n",
    "    (\"I love programming in Python.\", \"The recipe calls for two eggs.\"),\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for s1, s2 in pairs:\n",
    "    base_embs = base_model.encode([s1, s2])\n",
    "    ft_embs = ft_model.encode([s1, s2])\n",
    "    base_sim = cosine_similarity([base_embs[0]], [base_embs[1]])[0, 0]\n",
    "    ft_sim = cosine_similarity([ft_embs[0]], [ft_embs[1]])[0, 0]\n",
    "    rows.append({\n",
    "        \"sent1\": s1[:50],\n",
    "        \"sent2\": s2[:50],\n",
    "        \"base_cos\": f\"{base_sim:.4f}\",\n",
    "        \"ft_cos\": f\"{ft_sim:.4f}\",\n",
    "        \"delta\": f\"{ft_sim - base_sim:+.4f}\",\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Similarity heatmaps\n",
    "\n",
    "Visualise the full pairwise similarity matrix for a set of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentences = [\n",
    "    \"A man is playing guitar.\",\n",
    "    \"Someone is playing a musical instrument.\",\n",
    "    \"A woman is cooking dinner.\",\n",
    "    \"She is preparing a meal in the kitchen.\",\n",
    "    \"The dog is running in the park.\",\n",
    "    \"A puppy plays fetch outside.\",\n",
    "    \"The stock market rose sharply.\",\n",
    "    \"Financial markets saw significant gains.\",\n",
    "]\n",
    "\n",
    "labels = [s[:35] + \"...\" if len(s) > 35 else s for s in sentences]\n",
    "\n",
    "base_embs = np.array(base_model.encode(sentences))\n",
    "ft_embs = np.array(ft_model.encode(sentences))\n",
    "\n",
    "base_sim_mat = cosine_similarity(base_embs)\n",
    "ft_sim_mat = cosine_similarity(ft_embs)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for ax, mat, title in [(ax1, base_sim_mat, \"Base Model\"), (ax2, ft_sim_mat, \"Fine-tuned Model\")]:\n",
    "    im = ax.imshow(mat, cmap=\"RdYlGn\", vmin=-0.2, vmax=1.0)\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax.set_yticklabels(labels, fontsize=8)\n",
    "    ax.set_title(title)\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            ax.text(j, i, f\"{mat[i,j]:.2f}\", ha=\"center\", va=\"center\", fontsize=7)\n",
    "\n",
    "fig.colorbar(im, ax=[ax1, ax2], shrink=0.8, label=\"cosine similarity\")\n",
    "plt.suptitle(\"Pairwise Cosine Similarity: Base vs Fine-tuned\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. t-SNE visualisation\n",
    "\n",
    "Project embeddings to 2D to see if semantically similar sentences cluster together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "cluster_sentences = [\n",
    "    # Animals\n",
    "    \"The cat sat on the windowsill.\",\n",
    "    \"A dog chased its tail in the yard.\",\n",
    "    \"The birds were singing in the morning.\",\n",
    "    \"A rabbit hopped across the garden.\",\n",
    "    # Technology\n",
    "    \"The new smartphone has an excellent camera.\",\n",
    "    \"AI models are getting more powerful each year.\",\n",
    "    \"The software update fixed several bugs.\",\n",
    "    \"Cloud computing has transformed the industry.\",\n",
    "    # Food\n",
    "    \"The pasta was cooked to perfection.\",\n",
    "    \"She baked a chocolate cake for the party.\",\n",
    "    \"The restaurant serves excellent sushi.\",\n",
    "    \"Fresh vegetables make a great salad.\",\n",
    "]\n",
    "cluster_labels = [\"Animals\"] * 4 + [\"Technology\"] * 4 + [\"Food\"] * 4\n",
    "colors = {\"Animals\": \"tab:blue\", \"Technology\": \"tab:orange\", \"Food\": \"tab:green\"}\n",
    "\n",
    "ft_embs = np.array(ft_model.encode(cluster_sentences))\n",
    "base_embs = np.array(base_model.encode(cluster_sentences))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, embs, title in [(ax1, base_embs, \"Base Model\"), (ax2, ft_embs, \"Fine-tuned Model\")]:\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=4)\n",
    "    coords = tsne.fit_transform(embs)\n",
    "    for label in colors:\n",
    "        mask = [l == label for l in cluster_labels]\n",
    "        ax.scatter(coords[mask, 0], coords[mask, 1], c=colors[label], label=label, s=80, edgecolors=\"black\")\n",
    "    for i, txt in enumerate(cluster_sentences):\n",
    "        ax.annotate(txt[:25] + \"...\", (coords[i, 0], coords[i, 1]), fontsize=6, alpha=0.7)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.suptitle(\"t-SNE: Embedding Clusters\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Interactive: try your own sentences\n",
    "\n",
    "Edit the sentences below and re-run to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I reset my password?\"\n",
    "candidates = [\n",
    "    \"Click 'Forgot Password' on the login page.\",\n",
    "    \"You can change your password in account settings.\",\n",
    "    \"Our office is located in downtown Seattle.\",\n",
    "    \"The weather forecast calls for rain tomorrow.\",\n",
    "    \"Password recovery is available via email verification.\",\n",
    "]\n",
    "\n",
    "query_emb = ft_model.encode([query])[0]\n",
    "cand_embs = ft_model.encode(candidates)\n",
    "\n",
    "sims = [cosine_similarity([query_emb], [e])[0, 0] for e in cand_embs]\n",
    "ranked = sorted(zip(candidates, sims), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"{'Rank':<5} {'Similarity':<12} Candidate\")\n",
    "print(\"-\" * 70)\n",
    "for i, (cand, sim) in enumerate(ranked, 1):\n",
    "    print(f\"{i:<5} {sim:<12.4f} {cand}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Embedding drift: how much did fine-tuning change the representations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ds = load_from_disk(\"../data/processed/\")\n",
    "sample_texts = ds.shuffle(seed=42).select(range(200))[\"sent0\"]\n",
    "\n",
    "base_embs = np.array(base_model.encode(sample_texts))\n",
    "ft_embs = np.array(ft_model.encode(sample_texts))\n",
    "\n",
    "# Per-sentence cosine similarity between base and fine-tuned\n",
    "drifts = [cosine_similarity([b], [f])[0, 0] for b, f in zip(base_embs, ft_embs)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.hist(drifts, bins=40, edgecolor=\"black\", alpha=0.7)\n",
    "ax.axvline(np.median(drifts), color=\"red\", linestyle=\"--\", label=f\"median={np.median(drifts):.4f}\")\n",
    "ax.set_xlabel(\"Cosine similarity (base vs fine-tuned embedding)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Embedding Drift: How much did fine-tuning change each sentence?\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean drift (cos sim): {np.mean(drifts):.4f}\")\n",
    "print(f\"Min: {np.min(drifts):.4f}, Max: {np.max(drifts):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}